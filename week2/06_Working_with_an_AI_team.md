# Semana 2 ‚Äì Colabora√ß√£o com times de IA

## Como colaborar com um time de IA

### Come√ßando um projeto com um time de IA

- Mesmo sem engenheiros de IA dispon√≠veis, √© poss√≠vel come√ßar:
  - Incentive engenheiros a fazer cursos online de **Machine Learning / Deep Learning**.
  - Conhecimento introdut√≥rio j√° √© suficiente para iniciar projetos vi√°veis.

---

## Especifica√ß√£o de crit√©rios de aceita√ß√£o

- Defina uma **meta clara de desempenho** para o sistema de IA.
  - Ex: "Detectar defeitos em canecas com **95% de acur√°cia**".

### Como medir essa acur√°cia?

- √â necess√°rio um **conjunto de dados com r√≥tulos corretos**.
- Este conjunto √© chamado de **test set**:
  - Ex: imagens de canecas com r√≥tulos indicando se s√£o ‚Äúok‚Äù ou ‚Äúdefeituosas‚Äù.
  - Pode conter poucas centenas ou milhares de exemplos, dependendo do problema.
- A meta de acur√°cia √© **estat√≠stica**, e n√£o determin√≠stica:
  - Ex: 95% de acur√°cia m√©dia, e n√£o perfei√ß√£o em todos os casos.

> üéØ *Como dev:* j√° pense em como os dados de produ√ß√£o podem ser versionados, rotulados e mantidos de forma audit√°vel para treinamento e valida√ß√£o.

---

## Como times de IA pensam sobre dados

- Dois principais conjuntos:
  - **Training set**: usado para treinar o modelo (A ‚ûù B).
  - **Test set**: usado para avaliar o modelo de forma objetiva.

### Outras divis√µes comuns

- Muitos times tamb√©m usam:
  - **Validation set** (tamb√©m chamado de dev set): para afinar hiperpar√¢metros.
  - **Final test set**: usado apenas no final, sem vi√©s de ajuste.

> üß™ *Insight t√©cnico:* pense no split em 70/15/15 (train/val/test) como padr√£o inicial, mas adapt√°vel conforme o volume e a complexidade do dado.

---

## Expectativas realistas: evite exigir 100% de acur√°cia

### Por que 100% √© irreal?

1. **Limita√ß√µes do estado da arte**: ML ainda n√£o resolve tudo.
2. **Poucos dados**: modelos precisam de exemplos representativos.
3. **Dados sujos ou com r√≥tulos errados**.
4. **Ambiguidade intr√≠nseca nos exemplos**:
   - Ex: risco de especialistas discordarem sobre se um item √© defeituoso ou n√£o.

### Estrat√©gias para mitigar:

- Coletar mais dados.
- **Limpar r√≥tulos** com revis√£o humana.
- Definir crit√©rios claros de **classifica√ß√£o amb√≠gua**.

> ‚ö†Ô∏è *Como desenvolvedor:* contribua no desenho do pipeline de **valida√ß√£o cruzada**, gerenciamento de **data drift** e **consist√™ncia de labels** com ferramentas como DVC, Weights & Biases, ou frameworks internos.

---

## Resumo final da semana

- Aprendemos a:
  - Selecionar projetos vi√°veis e valiosos (interse√ß√£o entre IA e neg√≥cio).
  - Conduzir dilig√™ncia t√©cnica, de neg√≥cio e √©tica.
  - Colaborar com times de IA, entendendo como pensam sobre dados.
- Evite tentar reinventar a roda em componentes padr√£o.
- Use m√©tricas realistas e tenha clareza de dados desde o in√≠cio.

---

### ‚úÖ Pr√≥ximo passo: ver como projetos de IA se encaixam no contexto organizacional e sua escalabilidade